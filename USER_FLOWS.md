# EduPlanner DSA: Typical User Journeys

This document outlines common scenarios, or "user flows," to illustrate how a professor would interact with the EduPlanner DSA platform. These stories are designed to show the practical application of the AI-powered tools in a real-world teaching context.

Story 1: [The Professors and the EduPlanner DSA System](https://g.co/gemini/share/0cf5e4a584f0)

---

### **Scenario 1: Proactive Intervention for a Struggling Student**

**Persona:** Professor Anya, a diligent but busy computer science professor. She wants to identify and help students before they fall too far behind.

**The Journey:**

1.  **Morning Check-in:** Anya starts her day by logging into the EduPlanner **Dashboard**. The first thing she sees is the **Alerts Panel**. A "Critical" alert, flagged by the **Analyst agent**, catches her eye: *"High Failure Rate: Merge Sort Quiz. Over 60% of students failed."*

2.  **Identifying the Student:** The alert names a few students, including "Charlie." On the **Student Progress Heatmap**, she sees Charlie's icon is colored red, indicating he is "Struggling." She clicks on his icon.

3.  **Drilling Down into the Data:** This opens the **Student Detail Modal**. Here, Anya gets a complete picture of Charlie's situation: low scores on recent quizzes, a late assignment, and a drop in activity.

4.  **Seeking AI-Powered Insight:** To understand the root cause, Anya clicks the **"Generate Feedback"** button. The **Analyst agent** instantly processes Charlie's data and provides a summary:
    > *"Key Observations: Charlie consistently scores below average on topics involving recursion. His activity logs show him re-watching the 'Collision Resolution' video multiple times, suggesting a foundational gap."*
    > *"Recommendations: Assign targeted remedial work on basic recursion before moving to more complex tree-based algorithms."*

5.  **Taking Action:** Armed with this specific insight, Anya clicks the **"Assign Remedial Work"** button within the same modal. A new window appears, where the **Analyst agent** suggests a pre-made "Recursion Fundamentals" practice set. Anya approves the assignment with a single click.

**Outcome:** In less than five minutes, Professor Anya has moved from a high-level class alert to a deep, data-driven understanding of a single student's struggle, and has assigned a targeted intervention, all with the help of the AI Analyst.

---

### **Scenario 2: The Rapid Content Design and Quality Loop**

**Persona:** Professor Ben, who is preparing a new unit on Graph Algorithms. He wants to create high-quality teaching materials efficiently.

**The Journey:**

1.  **Creating a New Lesson:** Ben navigates to the **Instructional Design Lab**. He uses the **Lesson Plan Generator**, typing in the topic "Dijkstra's Algorithm," a few key learning objectives, and setting the difficulty to "Intermediate."

2.  **Instant First Draft:** He clicks "Generate." The **Optimizer agent** works for a few seconds and produces a complete, well-structured lesson plan, including section details, code examples, and assessment questions.

3.  **Requesting a Peer Review:** The draft looks good, but Ben wants an objective opinion on its effectiveness. He clicks the **"Send to Evaluator for Review"** button.

4.  **Collaborating with the AI Team:** The system automatically takes him to the **AI Workshop**. A message is already waiting in the chat interface, as if he'd typed it himself: *"Agent Evaluator, please review and provide a CIDPP-based analysis for the following lesson plan: Dijkstra's Algorithm."*

5.  **Getting Expert Feedback:** The **Evaluator agent** replies with a structured report:
    > *"**Strong Points:** The lesson has excellent Clarity (C) and Practicality (P)..."*
    > *"**Weak Points:** The Interactivity (I) score is low. The assessment questions primarily test rote memorization rather than application."*
    > *"**Recommendation:** I suggest tasking the **Optimizer Agent** to add an interactive, step-by-step walkthrough example and revise two assessment questions to be coding problems."*

6.  **One-Click Refinement:** The Evaluator's message contains a convenient button: **"Ask Optimizer to act on this feedback."** Ben clicks it.

7.  **Viewing the Final Product:** The **Optimizer agent** confirms it has incorporated the changes and provides a link: **"View Updated Lesson Plan."** Clicking this takes Ben back to the Design Lab, where the improved, more interactive lesson plan is ready to be used.

**Outcome:** Professor Ben went from an idea to a peer-reviewed, high-quality, and refined lesson plan in a fraction of the time it would normally take, using a seamless, collaborative loop between the AI agents.

---

### **Scenario 3: Class-Wide Analysis and Assessment Improvement**

**Persona:** Professor Carla, reflecting on her mid-term exam results. She suspects one of the topics was a major hurdle for the entire class.

**The Journey:**

1.  **Getting a Bird's-Eye View:** Carla goes to the **Student Observatory**. The **Student Scatter Plot** immediately visualizes her suspicion: she sees a large cluster of students grouped in the "high progress, low score" quadrant. This means many students did the work but still performed poorly, often indicating a problem with the teaching materials or assessment.

2.  **Asking the AI for a Deeper Look:** She clicks the **"Generate Insights"** button. The **Analyst agent** analyzes the plot and reports: *"A significant student cluster in the 'High Effort, Low Reward' quadrant suggests a potential content bottleneck. Performance data indicates this is strongly correlated with the 'Hash Table Concepts Quiz'."*

3.  **Investigating the Asset:** With this lead, Carla navigates to the **Evaluation & Optimization Center**. She selects the "Hash Table Concepts Quiz" from her list of assets.

4.  **Diagnosing the Problem:** She clicks **"Start Evaluation."** The **Evaluator agent** reviews the quiz and provides its feedback:
    > *"Analysis: Question #2, 'What is the ideal average-case time complexity for insertion?', is ambiguously worded and could be interpreted in multiple ways. Question #3 tests an edge case not sufficiently covered in the lesson materials."*

5.  **Automated Optimization:** The diagnosis is clear. Carla now clicks **"Optimize with AI."**

6.  **Reviewing the Changes:** The **Optimizer agent** rewrites the questions based on the Evaluator's feedback. The system then presents a **Comparison View**, showing the original questions and the new, improved versions side-by-side. The changes are clear and address the identified issues perfectly.

7.  **Committing the Improvement:** Confident in the changes, Carla clicks **"Save Optimized Version."** The improved quiz is now saved and ready for the next semester.

**Outcome:** Professor Carla used a high-level class visualization to pinpoint a problem, used AI to diagnose the specific issues in an assessment, and then used AI again to automatically fix it, improving the learning experience for all future students.
